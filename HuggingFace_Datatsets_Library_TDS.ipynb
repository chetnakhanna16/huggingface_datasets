{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import list_datasets, load_dataset\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datasets in the Datasets library:  952 \n",
      "\n",
      "\n",
      "['acronym_identification', 'ade_corpus_v2', 'adversarial_qa', 'aeslc',\n",
      " 'afrikaans_ner_corpus', 'ag_news', 'ai2_arc', 'air_dialogue',\n",
      " 'ajgt_twitter_ar', 'allegro_reviews', 'allocine', 'alt', 'amazon_polarity',\n",
      " 'amazon_reviews_multi', 'amazon_us_reviews', 'ambig_qa', 'amttl', 'anli',\n",
      " 'app_reviews', 'aqua_rat', 'aquamuse', 'ar_cov19', 'ar_res_reviews',\n",
      " 'ar_sarcasm', 'arabic_billion_words', 'arabic_pos_dialect',\n",
      " 'arabic_speech_corpus', 'arcd', 'arsentd_lev', 'art', 'arxiv_dataset',\n",
      " 'ascent_kb', 'aslg_pc12', 'asnq', 'asset', 'assin', 'assin2', 'atomic',\n",
      " 'autshumato', 'babi_qa', 'banking77', 'bbaw_egyptian', 'bbc_hindi_nli',\n",
      " 'bc2gm_corpus', 'best2009', 'bianet', 'bible_para', 'big_patent', 'billsum',\n",
      " 'bing_coronavirus_query_set', 'biomrc', 'blended_skill_talk', 'blimp',\n",
      " 'blog_authorship_corpus', 'bn_hate_speech', 'bookcorpus', 'bookcorpusopen',\n",
      " 'boolq', 'bprec', 'break_data', 'brwac', 'bsd_ja_en', 'bswac', 'c3', 'c4',\n",
      " 'cail2018', 'caner', 'capes', 'catalonia_independence', 'cawac', 'cbt',\n",
      " 'cc100', 'cc_news', 'ccaligned_multilingual', 'cdsc', 'cdt', 'cfq', 'chr_en',\n",
      " 'cifar10', 'cifar100', 'circa', 'civil_comments', 'clickbait_news_bg',\n",
      " 'climate_fever', 'clinc_oos', 'clue', 'cmrc2018', 'cnn_dailymail',\n",
      " 'coached_conv_pref', 'coarse_discourse', 'codah', 'code_search_net',\n",
      " 'code_x_glue_cc_clone_detection_big_clone_bench',\n",
      " 'code_x_glue_cc_clone_detection_poj104', 'code_x_glue_cc_cloze_testing_all',\n",
      " 'code_x_glue_cc_cloze_testing_maxmin', 'code_x_glue_cc_code_completion_line',\n",
      " 'code_x_glue_cc_code_completion_token', 'code_x_glue_cc_code_refinement',\n",
      " 'code_x_glue_cc_code_to_code_trans', 'code_x_glue_cc_defect_detection',\n",
      " 'code_x_glue_ct_code_to_text', 'code_x_glue_tc_nl_code_search_adv',\n",
      " 'code_x_glue_tc_text_to_code', 'code_x_glue_tt_text_to_text', 'com_qa',\n",
      " 'common_gen', 'common_voice', 'commonsense_qa', 'compguesswhat', 'conceptnet5',\n",
      " 'conll2000', 'conll2002', 'conll2003', 'conllpp', 'conv_ai', 'conv_ai_2',\n",
      " 'conv_ai_3', 'conv_questions', 'coqa', 'cord19', 'cornell_movie_dialog',\n",
      " 'cos_e', 'cosmos_qa', 'counter', 'covid_qa_castorini', 'covid_qa_deepset',\n",
      " 'covid_qa_ucsd', 'covid_tweets_japanese', 'covost2', 'craigslist_bargains',\n",
      " 'crawl_domain', 'crd3', 'crime_and_punish', 'crows_pairs', 'cryptonite',\n",
      " 'cs_restaurants', 'cuad', 'curiosity_dialogs', 'daily_dialog', 'dane',\n",
      " 'danish_political_comments', 'dart', 'datacommons_factcheck', 'dbpedia_14',\n",
      " 'dbrd', 'deal_or_no_dialog', 'definite_pronoun_resolution', 'dengue_filipino',\n",
      " 'dialog_re', 'diplomacy_detection', 'disaster_response_messages', 'discofuse',\n",
      " 'discovery', 'doc2dial', 'docred', 'doqa', 'dream', 'drop', 'duorc',\n",
      " 'dutch_social', 'dyk', 'e2e_nlg', 'e2e_nlg_cleaned', 'ecb', 'ecthr_cases',\n",
      " 'ehealth_kd', 'eitb_parcc', 'eli5', 'emea', 'emo', 'emotion', 'emotone_ar',\n",
      " 'empathetic_dialogues', 'enriched_web_nlg', 'eraser_multi_rc', 'esnli',\n",
      " 'eth_py150_open', 'ethos', 'eu_regulatory_ir', 'eurlex', 'euronews',\n",
      " 'europa_eac_tm', 'europa_ecdc_tm', 'europarl_bilingual', 'event2Mind',\n",
      " 'evidence_infer_treatment', 'exams', 'factckbr', 'fake_news_english',\n",
      " 'fake_news_filipino', 'farsi_news', 'fashion_mnist', 'fever', 'few_rel',\n",
      " 'financial_phrasebank', 'finer', 'flores', 'flue', 'fquad', 'freebase_qa',\n",
      " 'gap', 'gem', 'generated_reviews_enth', 'generics_kb',\n",
      " 'german_legal_entity_recognition', 'germaner', 'germeval_14', 'giga_fren',\n",
      " 'gigaword', 'glucose', 'glue', 'gnad10', 'go_emotions', 'gooaq',\n",
      " 'google_wellformed_query', 'grail_qa', 'great_code', 'guardian_authorship',\n",
      " 'gutenberg_time', 'hans', 'hansards', 'hard', 'harem', 'has_part',\n",
      " 'hate_offensive', 'hate_speech18', 'hate_speech_filipino',\n",
      " 'hate_speech_offensive', 'hate_speech_pl', 'hate_speech_portuguese',\n",
      " 'hatexplain', 'hausa_voa_ner', 'hausa_voa_topics', 'hda_nli_hindi', 'head_qa',\n",
      " 'health_fact', 'hebrew_projectbenyehuda', 'hebrew_sentiment',\n",
      " 'hebrew_this_world', 'hellaswag', 'hendrycks_test', 'hind_encorp',\n",
      " 'hindi_discourse', 'hippocorpus', 'hkcancor', 'hlgd', 'hope_edi', 'hotpot_qa',\n",
      " 'hover', 'hrenwac_para', 'hrwac', 'humicroedit', 'hybrid_qa',\n",
      " 'hyperpartisan_news_detection', 'iapp_wiki_qa_squad', 'id_clickbait',\n",
      " 'id_liputan6', 'id_nergrit_corpus', 'id_newspapers_2018', 'id_panl_bppt',\n",
      " 'id_puisi', 'igbo_english_machine_translation', 'igbo_monolingual', 'igbo_ner',\n",
      " 'ilist', 'imdb', 'imdb_urdu_reviews', 'imppres', 'indic_glue', 'indonlu',\n",
      " 'inquisitive_qg', 'interpress_news_category_tr',\n",
      " 'interpress_news_category_tr_lite', 'irc_disentangle', 'isixhosa_ner_corpus',\n",
      " 'isizulu_ner_corpus', 'iwslt2017', 'jeopardy', 'jfleg', 'jigsaw_toxicity_pred',\n",
      " 'jnlpba', 'journalists_questions', 'kannada_news', 'kd_conv', 'kde4', 'kelm',\n",
      " 'kilt_tasks', 'kilt_wikipedia', 'kinnews_kirnews', 'klue', 'kor_3i4k',\n",
      " 'kor_hate', 'kor_ner', 'kor_nli', 'kor_nlu', 'kor_qpair', 'kor_sae',\n",
      " 'kor_sarcasm', 'labr', 'lama', 'lambada', 'large_spanish_corpus', 'laroseda',\n",
      " 'lc_quad', 'lener_br', 'liar', 'librispeech_asr', 'librispeech_lm', 'limit',\n",
      " 'lince', 'linnaeus', 'liveqa', 'lj_speech', 'lm1b', 'lst20', 'm_lama',\n",
      " 'mac_morpho', 'makhzan', 'math_dataset', 'math_qa', 'matinf', 'mc_taco',\n",
      " 'md_gender_bias', 'mdd', 'med_hop', 'medal', 'medical_dialog',\n",
      " 'medical_questions_pairs', 'menyo20k_mt', 'meta_woz', 'metooma', 'metrec',\n",
      " 'miam', 'mkb', 'mkqa', 'mlqa', 'mlsum', 'mnist', 'mocha', 'moroco',\n",
      " 'movie_rationales', 'mrqa', 'ms_marco', 'ms_terms', 'msr_genomics_kbcomp',\n",
      " 'msr_sqa', 'msr_text_compression', 'msr_zhen_translation_parity', 'msra_ner',\n",
      " 'mt_eng_vietnamese', 'muchocine', 'multi_booked', 'multi_news', 'multi_nli',\n",
      " 'multi_nli_mismatch', 'multi_para_crawl', 'multi_re_qa', 'multi_woz_v22',\n",
      " 'multi_x_science_sum', 'mutual_friends', 'mwsc', 'myanmar_news', 'narrativeqa',\n",
      " 'narrativeqa_manual', 'natural_questions', 'ncbi_disease', 'nchlt', 'ncslgr',\n",
      " 'nell', 'neural_code_search', 'news_commentary', 'newsgroup', 'newsph',\n",
      " 'newsph_nli', 'newspop', 'newsqa', 'newsroom', 'nkjp-ner', 'nli_tr',\n",
      " 'nlu_evaluation_data', 'norec', 'norne', 'norwegian_ner', 'nq_open', 'nsmc',\n",
      " 'numer_sense', 'numeric_fused_head', 'oclar', 'offcombr', 'offenseval2020_tr',\n",
      " 'offenseval_dravidian', 'ofis_publik', 'ohsumed', 'ollie', 'omp',\n",
      " 'onestop_english', 'open_subtitles', 'openbookqa', 'openslr', 'openwebtext',\n",
      " 'opinosis', 'opus100', 'opus_books', 'opus_dgt', 'opus_dogc', 'opus_elhuyar',\n",
      " 'opus_euconst', 'opus_finlex', 'opus_fiskmo', 'opus_gnome', 'opus_infopankki',\n",
      " 'opus_memat', 'opus_montenegrinsubs', 'opus_openoffice', 'opus_paracrawl',\n",
      " 'opus_rf', 'opus_tedtalks', 'opus_ubuntu', 'opus_wikipedia', 'opus_xhosanavy',\n",
      " 'orange_sum', 'oscar', 'para_crawl', 'para_pat',\n",
      " 'parsinlu_reading_comprehension', 'paws', 'paws-x', 'pec', 'peer_read',\n",
      " 'peoples_daily_ner', 'per_sent', 'persian_ner', 'pg19', 'php', 'piaf', 'pib',\n",
      " 'piqa', 'pn_summary', 'poem_sentiment', 'polemo2', 'poleval2019_cyberbullying',\n",
      " 'poleval2019_mt', 'polsum', 'polyglot_ner', 'prachathai67k', 'pragmeval',\n",
      " 'proto_qa', 'psc', 'ptb_text_only', 'pubmed', 'pubmed_qa', 'py_ast', 'qa4mre',\n",
      " 'qa_srl', 'qa_zre', 'qangaroo', 'qanta', 'qasc', 'qasper', 'qed', 'qed_amara',\n",
      " 'quac', 'quail', 'quarel', 'quartz', 'quora', 'quoref', 'race', 're_dial',\n",
      " 'reasoning_bg', 'recipe_nlg', 'reclor', 'reddit', 'reddit_tifu', 'refresd',\n",
      " 'reuters21578', 'ro_sent', 'ro_sts', 'ro_sts_parallel', 'roman_urdu', 'ronec',\n",
      " 'ropes', 'rotten_tomatoes', 's2orc', 'samsum', 'sanskrit_classic',\n",
      " 'saudinewsnet', 'scan', 'scb_mt_enth_2020', 'schema_guided_dstc8', 'scicite',\n",
      " 'scielo', 'scientific_papers', 'scifact', 'sciq', 'scitail', 'scitldr',\n",
      " 'search_qa', 'selqa', 'sem_eval_2010_task_8', 'sem_eval_2014_task_1',\n",
      " 'sem_eval_2020_task_11', 'sent_comp', 'senti_lex', 'senti_ws', 'sentiment140',\n",
      " 'sepedi_ner', 'sesotho_ner_corpus', 'setimes', 'setswana_ner_corpus', 'sharc',\n",
      " 'sharc_modified', 'sick', 'silicone', 'simple_questions_v2',\n",
      " 'siswati_ner_corpus', 'smartdata', 'sms_spam', 'snips_built_in_intents',\n",
      " 'snli', 'snow_simplified_japanese_corpus', 'so_stacksample',\n",
      " 'social_bias_frames', 'social_i_qa', 'sofc_materials_articles', 'sogou_news',\n",
      " 'spanish_billion_words', 'spc', 'species_800', 'spider', 'squad',\n",
      " 'squad_adversarial', 'squad_es', 'squad_it', 'squad_kor_v1', 'squad_kor_v2',\n",
      " 'squad_v1_pt', 'squad_v2', 'squadshifts', 'srwac', 'sst', 'stereoset',\n",
      " 'stsb_mt_sv', 'stsb_multi_mt', 'style_change_detection', 'subjqa',\n",
      " 'super_glue', 'swag', 'swahili', 'swahili_news', 'swda', 'swedish_ner_corpus',\n",
      " 'swedish_reviews', 'tab_fact', 'tamilmixsentiment', 'tanzil', 'tapaco',\n",
      " 'tashkeela', 'taskmaster1', 'taskmaster2', 'taskmaster3', 'tatoeba',\n",
      " 'ted_hrlr', 'ted_iwlst2013', 'ted_multi', 'ted_talks_iwslt', 'telugu_books',\n",
      " 'telugu_news', 'tep_en_fa_para', 'thai_toxicity_tweet', 'thainer',\n",
      " 'thaiqa_squad', 'thaisum', 'tilde_model', 'times_of_india_news_headlines',\n",
      " 'timit_asr', 'tiny_shakespeare', 'tlc', 'tmu_gfm_dataset', 'totto', 'trec',\n",
      " 'trivia_qa', 'tsac', 'ttc4900', 'tunizi', 'tuple_ie', 'turk',\n",
      " 'turkish_movie_sentiment', 'turkish_ner', 'turkish_product_reviews',\n",
      " 'turkish_shrinked_ner', 'turku_ner_corpus', 'tweet_eval', 'tweet_qa',\n",
      " 'tweets_ar_en_parallel', 'tweets_hate_speech_detection', 'twi_text_c3',\n",
      " 'twi_wordsim353', 'tydiqa', 'ubuntu_dialogs_corpus', 'udhr', 'um005', 'un_ga',\n",
      " 'un_multi', 'un_pc', 'universal_dependencies', 'universal_morphologies',\n",
      " 'urdu_fake_news', 'urdu_sentiment_corpus', 'web_nlg', 'web_of_science',\n",
      " 'web_questions', 'weibo_ner', 'wi_locness', 'wiki40b', 'wiki_asp',\n",
      " 'wiki_atomic_edits', 'wiki_auto', 'wiki_bio', 'wiki_dpr', 'wiki_hop',\n",
      " 'wiki_lingua', 'wiki_movies', 'wiki_qa', 'wiki_qa_ar', 'wiki_snippets',\n",
      " 'wiki_source', 'wiki_split', 'wiki_summary', 'wikiann', 'wikicorpus',\n",
      " 'wikihow', 'wikipedia', 'wikisql', 'wikitext', 'wikitext_tl39', 'wili_2018',\n",
      " 'wino_bias', 'winograd_wsc', 'winogrande', 'wiqa', 'wisesight1000',\n",
      " 'wisesight_sentiment', 'wmt14', 'wmt15', 'wmt16', 'wmt17', 'wmt18', 'wmt19',\n",
      " 'wmt20_mlqe_task1', 'wmt20_mlqe_task2', 'wmt20_mlqe_task3', 'wmt_t2t',\n",
      " 'wnut_17', 'wongnai_reviews', 'woz_dialogue', 'wrbsc', 'x_stance', 'xcopa',\n",
      " 'xed_en_fi', 'xglue', 'xnli', 'xor_tydi_qa', 'xquad', 'xquad_r', 'xsum',\n",
      " 'xsum_factuality', 'xtreme', 'yahoo_answers_qa', 'yahoo_answers_topics',\n",
      " 'yelp_polarity', 'yelp_review_full', 'yoruba_bbc_topics', 'yoruba_gv_ner',\n",
      " 'yoruba_text_c3', 'yoruba_wordsim353', 'youtube_caption_corrections', 'zest',\n",
      " 'AConsApart/anime_subtitles_DialoGPT', 'Abdo1Kamr/Arabic_Nine_Hadiths_Books',\n",
      " 'AdWeeb/DravidianMT', 'Adnan/Urdu_News_Headlines', 'Akshith/aa',\n",
      " 'Akshith/g_rock', 'Akshith/test', 'Annielytics/DoctorsNotes', 'Avishekavi/Avi',\n",
      " 'Binbin/my_dataset', 'Darren/data', 'EMBO/biolang', 'EMBO/sd-nlp',\n",
      " 'Eymen3455/xsum_tr', 'FRTNX/cosuju', 'Firoj/CrisisBench',\n",
      " 'Fraser/mnist-text-default', 'Fraser/mnist-text-no-spaces',\n",
      " 'Fraser/mnist-text-small', 'Fraser/news-category-dataset',\n",
      " 'Fraser/python-lines', 'Fraser/short-jokes',\n",
      " 'Halilyesilceng/autonlp-data-nameEntityRecognition', 'HarleyQ/WitcherDialogue',\n",
      " 'Harveenchadha/Gujarati-Monolingual-Data', 'Jean-Baptiste/wikiner_fr',\n",
      " 'KETI-AIR/klue', 'KETI-AIR/kor_corpora', 'KETI-AIR/korquad', 'KETI-AIR/nikl',\n",
      " 'LIAMF-USP/arc-retrieval-c4', 'MKK/Dhivehi-English', 'MarianaSahagun/test',\n",
      " 'Melinoe/TheLabTexts', 'NTUYG/RAGTest', 'NbAiLab/norec_agg', 'NbAiLab/norne',\n",
      " 'NbAiLab/norwegian_parliament', 'Ofrit/tmp', 'QA/abk-eng',\n",
      " 'Remesita/tagged_reviews', 'SajjadAyoubi/persian_qa', 'TRoboto/masc',\n",
      " 'Tatyana/ru_sentiment_dataset', 'Terry0107/RiSAWOZ', 'TimTreasure4/Test',\n",
      " 'Trainmaster9977/957', 'Trainmaster9977/zbakuman',\n",
      " 'Tyler/wikimatrix_collapsed', 'Valahaar/wsdmt', 'Vishva/UniFAQ_DataSET',\n",
      " 'Wikidepia/IndoParaCrawl', 'Wikidepia/IndoSQuAD', 'XiangXiang/clt',\n",
      " 'Yves/fhnw_swiss_parliament', 'abhishek/autonlp-data-imdb_eval',\n",
      " 'abwicke/C-B-R', 'abwicke/koplo', 'adamlin/re_dial', 'ajmbell/test-dataset',\n",
      " 'alireza655/alireza655', 'allenai/c4', 'anukaver/EstQA', 'aschvin/fhnw_test',\n",
      " 'ashish-shrivastava/dont-know-dataset', 'astarostap/antisemitic-tweets',\n",
      " 'astarostap/antisemitic_tweets', 'athivvat/thai-rap-lyrics',\n",
      " 'ausgequetschtem/jtrddfhfgh', 'bavard/personachat_truecased',\n",
      " 'bemanningssitua/dplremjfjfj', 'berkergurcay/2020-10K-Reports',\n",
      " 'bsc/ancora-ca-ner', 'bsc/sts-ca', 'bsc/tecla', 'bsc/viquiquad',\n",
      " 'bsc/xquad-ca', 'caca/zscczs', 'canwenxu/dogwhistle', 'ccccccc/hdjw_94ejrjr',\n",
      " 'cdminix/mgb1', 'cemigo/taylor_vs_shakes', 'cemigo/test-data',\n",
      " 'cheulyop/ksponspeech', 'clarin-pl/cst-wikinews', 'clarin-pl/nkjp-pos',\n",
      " 'clarin-pl/polemo2-official', 'classla/copa_hr', 'classla/hr500k',\n",
      " 'classla/reldi_hr', 'classla/reldi_sr', 'classla/setimes_sr',\n",
      " 'cnrcastroli/aaaa', 'congpt/dstc23_asr', 'corypaik/prost',\n",
      " 'dasago78/dasago78dataset', 'dataset/wikipedia_bn', 'david-wb/zeshel',\n",
      " 'deepset/germandpr', 'deepset/germanquad', 'dfgvhxfgv/fghghj',\n",
      " 'dgknrsln/Yorumsepeti', 'dispenst/jhghdghfd', 'dispix/test-dataset',\n",
      " 'dynabench/dynasent', 'dynabench/qa', 'eason929/test', 'edfews/szdfcszdf',\n",
      " 'edsas/fgrdtgrdtdr', 'edsas/grttyi', 'ervis/aaa', 'ervis/qqq',\n",
      " 'fatvvs/autonlp-data-entity_model_conll2003', 'formermagic/github_python_1m',\n",
      " 'formu/CVT', 'fulai/DuReader', 'fuliucansheng/data_for_test',\n",
      " 'fvillena/cantemist', 'fvillena/spanish_diagnostics',\n",
      " 'german-nlp-group/german_common_crawl', 'godzillavskongonlinetv/ergfdg',\n",
      " 'godzillavskongonlinetv/godzillavskongfullmovie', 'gpt3mix/rt20',\n",
      " 'gpt3mix/sst2', 'gustavecortal/fr_covid_news', 'hartzeer/kdfjdshfje',\n",
      " 'hfface/poopi', 'huseinzol05/translated-The-Pile', 'iamshsdf/sssssssssss',\n",
      " 'jaimin/wav2vec2-large-xlsr-gujarati-demo', 'jdepoix/junit_test_completion',\n",
      " 'jglaser/binding_affinity', 'jimregan/clarinpl_sejmsenat',\n",
      " 'jimregan/clarinpl_studio', 'jmamou/augmented-glue-sst2', 'joelito/ler',\n",
      " 'joelito/sem_eval_2010_task_8', 'julien-c/dummy-dataset-from-colab',\n",
      " 'k-halid/ar', 'karinev/lanuitdudroit', 'katoensp/VR-OP', 'kmyoo/klue-tc-dev',\n",
      " 'lavis-nlp/german_legal_sentences', 'lewtun/binary_classification_dummy',\n",
      " 'lewtun/text_classification_dummy', 'lhoestq/custom_squad', 'lhoestq/squad',\n",
      " 'lhoestq/test', 'lhoestq/wikipedia_bn', 'lkiouiou/o9ui7877687',\n",
      " 'lohanna/testedjkcxkf', 'lucien/sciencemission', 'lucien/voacantonesed',\n",
      " 'lucien/wsaderfffjjjhhh', 'lucio/common_voice_eval',\n",
      " 'majod/CleanNaturalQuestionsDataset', 'makanan/umich', 'medzaf/test',\n",
      " 'metalearning/kaggale-nlp-tutorial', 'mksaad/Arabic_news',\n",
      " 'mmm-da/rutracker_anime_torrent_titles',\n",
      " 'mohsenfayyaz/toxicity-classification-datasets', 'mrojas/abbreviation',\n",
      " 'mrojas/body', 'mrojas/disease', 'mrojas/family', 'mrojas/finding',\n",
      " 'mrojas/medication', 'mrojas/procedure', 'mulcyber/europarl-mono',\n",
      " 'mustafa12/db_ee', 'mustafa12/edaaaas', 'mustafa12/thors',\n",
      " 'nateraw/cats-and-dogs', 'nateraw/fairface', 'nateraw/test',\n",
      " 'naver-clova-conversation/klue-tc-dev-tsv',\n",
      " 'naver-clova-conversation/klue-tc-tsv',\n",
      " 'naver-clova-conversation-ul/klue-tc-dev', 'nbroad/few-nerd',\n",
      " 'nucklehead/ht-voice-dataset', 'oelkrise/CRT', 'osanseviero/llama_test',\n",
      " 'parivartanayurveda/Malesexproblemsayurvedictreatment', 'pasinit/xlwic',\n",
      " 'patrickvonplaten/librispeech_asr_dummy',\n",
      " 'patrickvonplaten/scientific_papers_dummy', 'pdesoyres/test',\n",
      " 'peixian/equity_evaluation_corpus', 'peixian/rtGender', 'pelican/test_100',\n",
      " 'persiannlp/parsinlu_entailment', 'persiannlp/parsinlu_query_paraphrasing',\n",
      " 'persiannlp/parsinlu_reading_comprehension', 'persiannlp/parsinlu_sentiment',\n",
      " 'persiannlp/parsinlu_translation_en_fa',\n",
      " 'persiannlp/parsinlu_translation_fa_en', 'piEsposito/br-quad-2.0',\n",
      " 'piEsposito/br_quad_20', 'piEsposito/squad_20_ptbr',\n",
      " 'princeton-nlp/datasets-for-simcse', 'priya3301/Graduation_admission',\n",
      " 'priya3301/tes', 'priya3301/test', 'rewardsignal/reddit_writing_prompts',\n",
      " 'rony/soccer-dialogues', 'roskoN/dstc8-reddit-corpus',\n",
      " 'salesken/Paraphrase_category_detection', 'sdfufygvjh/fgghuviugviu',\n",
      " 'seamew/Weibo', 'seamew/amazon_reviews_zh', 'seamew/weibo_avg',\n",
      " 'shahrukhx01/questions-vs-statements', 'sharejing/BiPaR', 'sileod/metaeval',\n",
      " 'sismetanin/rureviews', 'smallv0221/my-test', 'somaimanguyat/Kankuroooo',\n",
      " 'somaimanguyat/Piscok', 'somaimanguyat/Resett', 'somaimanguyat/asunakirito',\n",
      " 'somaimanguyat/mamangjaprut', 'somaimanguyat/momoshiki',\n",
      " 'somaimanguyat/movie21', 'somaimanguyat/oonel', 'somaimanguyat/xiomay',\n",
      " 'spacemanidol/msmarco_passage_ranking', 'ssasaa/gghghgh',\n",
      " 'sshleifer/pseudo_bart_xsum', 'stas/openwebtext-10k',\n",
      " 'stas/wmt14-en-de-pre-processed', 'stas/wmt16-en-ro-pre-processed',\n",
      " 'stiel/skjdhjkasdhasjkd', 'subiksha/OwnDataset', 'susumu2357/squad_v2_sv',\n",
      " 'tals/test', 'tarudesu/UIT-ViCTSD', 'thiemowa/argumentationreviewcorpus',\n",
      " 'thiemowa/empathyreviewcorpus', 'tommy19970714/common_voice',\n",
      " 'tommy19970714/jsut_asr', 'tommy19970714/jsut_asr_hiragana',\n",
      " 'tommy19970714/jsut_asr_hiragana_small', 'tommy19970714/laborotvspeech',\n",
      " 'turingbench/TuringBench', 'uasoyasser/rgfes',\n",
      " 'vasudevgupta/bigbird-tokenized-natural-questions', 'vasudevgupta/data',\n",
      " 'vasudevgupta/natural-questions-validation',\n",
      " 'vasudevgupta/temperature-distribution-2d-plate',\n",
      " 'vasudevgupta/temperature-distribution-3d-cylinder', 'vctc92/sdsd',\n",
      " 'vctc92/test', 'versae/adobo', 'vershasaxena91/datasets',\n",
      " 'vershasaxena91/squad_multitask', 'w-nicole/childes_data',\n",
      " 'w11wo/imdb-javanese', 'webek18735/ddvoacantonesed', 'webek18735/dhikhscook',\n",
      " 'wmt/europarl', 'wmt/news-commentary', 'wmt/uncorpus', 'wmt/wikititles',\n",
      " 'wmt/wmt10', 'wmt/wmt13', 'wmt/wmt14', 'wmt/wmt15', 'wmt/wmt16', 'wmt/wmt17',\n",
      " 'wmt/wmt18', 'wmt/wmt19', 'yluisfern/PBU']\n"
     ]
    }
   ],
   "source": [
    "datasets = list_datasets()\n",
    "print(\"Number of datasets in the Datasets library: \", len(datasets), \"\\n\\n\")\n",
    "pprint(datasets, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author': None,\n",
      " 'citation': '@article{2016arXiv160605250R,\\n'\n",
      "             '       author = {{Rajpurkar}, Pranav and {Zhang}, Jian and '\n",
      "             '{Lopyrev},\\n'\n",
      "             '                 Konstantin and {Liang}, Percy},\\n'\n",
      "             '        title = \"{SQuAD: 100,000+ Questions for Machine '\n",
      "             'Comprehension of Text}\",\\n'\n",
      "             '      journal = {arXiv e-prints},\\n'\n",
      "             '         year = 2016,\\n'\n",
      "             '          eid = {arXiv:1606.05250},\\n'\n",
      "             '        pages = {arXiv:1606.05250},\\n'\n",
      "             'archivePrefix = {arXiv},\\n'\n",
      "             '       eprint = {1606.05250},\\n'\n",
      "             '}',\n",
      " 'description': 'Stanford Question Answering Dataset (SQuAD) is a reading '\n",
      "                'comprehension dataset, consisting of questions posed by '\n",
      "                'crowdworkers on a set of Wikipedia articles, where the answer '\n",
      "                'to every question is a segment of text, or span, from the '\n",
      "                'corresponding reading passage, or the question might be '\n",
      "                'unanswerable.',\n",
      " 'etag': None,\n",
      " 'id': 'squad',\n",
      " 'key': '',\n",
      " 'lastModified': None,\n",
      " 'paperswithcode_id': 'squad',\n",
      " 'siblings': None,\n",
      " 'size': None}\n"
     ]
    }
   ],
   "source": [
    "#dataset attributes \n",
    "squad = list_datasets(with_details=True)[datasets.index('squad')]\n",
    "pprint(squad.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/Users/ankurrastogi/.cache/huggingface/datasets/squad/plain_text/1.0.0/4fffa6cf76083860f85fa83486ec3028e7e32c342c218ff2a620fc6b2868483a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': Dataset({\n",
      "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "    num_rows: 87599\n",
      "}),\n",
      " 'validation': Dataset({\n",
      "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "    num_rows: 10570\n",
      "})}\n"
     ]
    }
   ],
   "source": [
    "squad_dataset = load_dataset('squad')\n",
    "pprint(squad_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset using split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/Users/ankurrastogi/.cache/huggingface/datasets/squad/plain_text/1.0.0/4fffa6cf76083860f85fa83486ec3028e7e32c342c218ff2a620fc6b2868483a)\n",
      "Reusing dataset squad (/Users/ankurrastogi/.cache/huggingface/datasets/squad/plain_text/1.0.0/4fffa6cf76083860f85fa83486ec3028e7e32c342c218ff2a620fc6b2868483a)\n"
     ]
    }
   ],
   "source": [
    "#loading dataset by selecting split\n",
    "squad_train = load_dataset('squad', split='train')\n",
    "squad_valid = load_dataset('squad', split='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset using configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Config name is missing.\nPlease pick one among the available configs: ['Wireless_v1_00', 'Watches_v1_00', 'Video_Games_v1_00', 'Video_DVD_v1_00', 'Video_v1_00', 'Toys_v1_00', 'Tools_v1_00', 'Sports_v1_00', 'Software_v1_00', 'Shoes_v1_00', 'Pet_Products_v1_00', 'Personal_Care_Appliances_v1_00', 'PC_v1_00', 'Outdoors_v1_00', 'Office_Products_v1_00', 'Musical_Instruments_v1_00', 'Music_v1_00', 'Mobile_Electronics_v1_00', 'Mobile_Apps_v1_00', 'Major_Appliances_v1_00', 'Luggage_v1_00', 'Lawn_and_Garden_v1_00', 'Kitchen_v1_00', 'Jewelry_v1_00', 'Home_Improvement_v1_00', 'Home_Entertainment_v1_00', 'Home_v1_00', 'Health_Personal_Care_v1_00', 'Grocery_v1_00', 'Gift_Card_v1_00', 'Furniture_v1_00', 'Electronics_v1_00', 'Digital_Video_Games_v1_00', 'Digital_Video_Download_v1_00', 'Digital_Software_v1_00', 'Digital_Music_Purchase_v1_00', 'Digital_Ebook_Purchase_v1_00', 'Camera_v1_00', 'Books_v1_00', 'Beauty_v1_00', 'Baby_v1_00', 'Automotive_v1_00', 'Apparel_v1_00', 'Digital_Ebook_Purchase_v1_01', 'Books_v1_01', 'Books_v1_02']\nExample of usage:\n\t`load_dataset('amazon_us_reviews', 'Wireless_v1_00')`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e29570369eff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#loading dataset by selecting configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mamazon_us_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'amazon_us_reviews'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamazon_us_reviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, ignore_verifications, keep_in_memory, save_infos, script_version, use_auth_token, task, **config_kwargs)\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0mhash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhash\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mconfig_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m     )\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/datasets/builder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, writer_batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGeneratorBasedBuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m         \u001b[0;31m# Batch size used by the ArrowWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0;31m# It defines the number of samples that are kept in memory before writing them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/datasets/builder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cache_dir, name, hash, features, **config_kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mcustom_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mconfig_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         )\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/datasets/builder.py\u001b[0m in \u001b[0;36m_create_builder_config\u001b[0;34m(self, name, custom_features, **config_kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m                         \u001b[0;34m\"Config name is missing.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                         \u001b[0;34m\"\\nPlease pick one among the available configs: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder_configs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m                         \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\nExample of usage:\\n\\t`{}`\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_of_usage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m                     )\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbuilder_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBUILDER_CONFIGS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Config name is missing.\nPlease pick one among the available configs: ['Wireless_v1_00', 'Watches_v1_00', 'Video_Games_v1_00', 'Video_DVD_v1_00', 'Video_v1_00', 'Toys_v1_00', 'Tools_v1_00', 'Sports_v1_00', 'Software_v1_00', 'Shoes_v1_00', 'Pet_Products_v1_00', 'Personal_Care_Appliances_v1_00', 'PC_v1_00', 'Outdoors_v1_00', 'Office_Products_v1_00', 'Musical_Instruments_v1_00', 'Music_v1_00', 'Mobile_Electronics_v1_00', 'Mobile_Apps_v1_00', 'Major_Appliances_v1_00', 'Luggage_v1_00', 'Lawn_and_Garden_v1_00', 'Kitchen_v1_00', 'Jewelry_v1_00', 'Home_Improvement_v1_00', 'Home_Entertainment_v1_00', 'Home_v1_00', 'Health_Personal_Care_v1_00', 'Grocery_v1_00', 'Gift_Card_v1_00', 'Furniture_v1_00', 'Electronics_v1_00', 'Digital_Video_Games_v1_00', 'Digital_Video_Download_v1_00', 'Digital_Software_v1_00', 'Digital_Music_Purchase_v1_00', 'Digital_Ebook_Purchase_v1_00', 'Camera_v1_00', 'Books_v1_00', 'Beauty_v1_00', 'Baby_v1_00', 'Automotive_v1_00', 'Apparel_v1_00', 'Digital_Ebook_Purchase_v1_01', 'Books_v1_01', 'Books_v1_02']\nExample of usage:\n\t`load_dataset('amazon_us_reviews', 'Wireless_v1_00')`"
     ]
    }
   ],
   "source": [
    "#loading dataset by selecting configuration\n",
    "amazon_us_reviews = load_dataset('amazon_us_reviews')\n",
    "print(amazon_us_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset amazon_us_reviews (/Users/ankurrastogi/.cache/huggingface/datasets/amazon_us_reviews/Watches_v1_00/0.1.0/17b2481be59723469538adeb8fd0a68b0ba363bbbdd71090e72c325ee6c7e563)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['marketplace', 'customer_id', 'review_id', 'product_id', 'product_parent', 'product_title', 'product_category', 'star_rating', 'helpful_votes', 'total_votes', 'vine', 'verified_purchase', 'review_headline', 'review_body', 'review_date'],\n",
      "        num_rows: 960872\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "amazon_us_reviews = load_dataset('amazon_us_reviews', 'Watches_v1_00')\n",
    "print(amazon_us_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training set:  87599\n",
      "Length of validation set:  10570\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of training set: \", len(squad_train))\n",
    "print(\"Length of validation set: \", len(squad_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First example from the dataset: \n",
      "\n",
      "{'answers': {'answer_start': [515], 'text': ['Saint Bernadette Soubirous']},\n",
      " 'context': 'Architecturally, the school has a Catholic character. Atop the '\n",
      "            \"Main Building's gold dome is a golden statue of the Virgin Mary. \"\n",
      "            'Immediately in front of the Main Building and facing it, is a '\n",
      "            'copper statue of Christ with arms upraised with the legend '\n",
      "            '\"Venite Ad Me Omnes\". Next to the Main Building is the Basilica '\n",
      "            'of the Sacred Heart. Immediately behind the basilica is the '\n",
      "            'Grotto, a Marian place of prayer and reflection. It is a replica '\n",
      "            'of the grotto at Lourdes, France where the Virgin Mary reputedly '\n",
      "            'appeared to Saint Bernadette Soubirous in 1858. At the end of the '\n",
      "            'main drive (and in a direct line that connects through 3 statues '\n",
      "            'and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
      " 'id': '5733be284776f41900661182',\n",
      " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes '\n",
      "             'France?',\n",
      " 'title': 'University_of_Notre_Dame'}\n"
     ]
    }
   ],
   "source": [
    "print(\"First example from the dataset: \\n\")\n",
    "pprint(squad_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two examples from the dataset using slice operation: \n",
      "\n",
      "{'answers': [{'answer_start': [675], 'text': ['Buechner Prize for Preaching']},\n",
      "             {'answer_start': [487], 'text': ['eight']}],\n",
      " 'context': ['The university is the major seat of the Congregation of Holy '\n",
      "             'Cross (albeit not its official headquarters, which are in Rome). '\n",
      "             'Its main seminary, Moreau Seminary, is located on the campus '\n",
      "             'across St. Joseph lake from the Main Building. Old College, the '\n",
      "             'oldest building on campus and located near the shore of St. Mary '\n",
      "             'lake, houses undergraduate seminarians. Retired priests and '\n",
      "             'brothers reside in Fatima House (a former retreat center), Holy '\n",
      "             'Cross House, as well as Columba Hall near the Grotto. The '\n",
      "             'university through the Moreau Seminary has ties to theologian '\n",
      "             'Frederick Buechner. While not Catholic, Buechner has praised '\n",
      "             'writers from Notre Dame and Moreau Seminary created a Buechner '\n",
      "             'Prize for Preaching.',\n",
      "             'The College of Engineering was established in 1920, however, '\n",
      "             'early courses in civil and mechanical engineering were a part of '\n",
      "             'the College of Science since the 1870s. Today the college, '\n",
      "             'housed in the Fitzpatrick, Cushing, and Stinson-Remick Halls of '\n",
      "             'Engineering, includes five departments of study – aerospace and '\n",
      "             'mechanical engineering, chemical and biomolecular engineering, '\n",
      "             'civil engineering and geological sciences, computer science and '\n",
      "             'engineering, and electrical engineering – with eight B.S. '\n",
      "             'degrees offered. Additionally, the college offers five-year dual '\n",
      "             'degree programs with the Colleges of Arts and Letters and of '\n",
      "             'Business awarding additional B.A. and Master of Business '\n",
      "             'Administration (MBA) degrees, respectively.'],\n",
      " 'id': ['5733bed24776f4190066118c', '5733a6424776f41900660f51'],\n",
      " 'question': ['Which prize did Frederick Buechner create?',\n",
      "              'How many BS level degrees are offered in the College of '\n",
      "              'Engineering at Notre Dame?'],\n",
      " 'title': ['University_of_Notre_Dame', 'University_of_Notre_Dame']}\n"
     ]
    }
   ],
   "source": [
    "print(\"Two examples from the dataset using slice operation: \\n\")\n",
    "pprint(squad_train[14:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A column slice from the dataset: \n",
      "\n",
      "['To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
      " 'What is in front of the Notre Dame Main Building?',\n",
      " 'The Basilica of the Sacred heart at Notre Dame is beside to which structure?',\n",
      " 'What is the Grotto at Notre Dame?',\n",
      " 'What sits on top of the Main Building at Notre Dame?']\n"
     ]
    }
   ],
   "source": [
    "print(\"A column slice from the dataset: \\n\")\n",
    "pprint(squad_train['question'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
      "To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n"
     ]
    }
   ],
   "source": [
    "print(squad_train['question'][0])\n",
    "print(squad_train[0]['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(squad_train['question'][0] == squad_train[0]['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'What is in front of the Notre Dame Main Building?', 'The Basilica of the Sacred heart at Notre Dame is beside to which structure?', 'What is the Grotto at Notre Dame?', 'What sits on top of the Main Building at Notre Dame?']\n",
      "['To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'What is in front of the Notre Dame Main Building?', 'The Basilica of the Sacred heart at Notre Dame is beside to which structure?', 'What is the Grotto at Notre Dame?', 'What sits on top of the Main Building at Notre Dame?']\n"
     ]
    }
   ],
   "source": [
    "print(squad_train['question'][:5])\n",
    "print(squad_train[:5]['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: \n",
      "{'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None),\n",
      " 'context': Value(dtype='string', id=None),\n",
      " 'id': Value(dtype='string', id=None),\n",
      " 'question': Value(dtype='string', id=None),\n",
      " 'title': Value(dtype='string', id=None)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Features: \")\n",
    "pprint(squad_train.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names:  ['answers', 'context', 'id', 'question', 'title']\n"
     ]
    }
   ],
   "source": [
    "print(\"Column names: \", squad_train.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  87599\n",
      "Number of columns:  5\n",
      "Shape:  (87599, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows: \", squad_train.num_rows)\n",
    "print(\"Number of columns: \", squad_train.num_columns)\n",
    "print(\"Shape: \", squad_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'title', 'context', 'question', 'answers', 'new_column'],\n",
      "    num_rows: 87599\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "new_column = [\"foo\"] * len(squad_train)\n",
    "squad_train = squad_train.add_column(\"new_column\", new_column)\n",
    "print(squad_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', 'foo', 'foo', 'foo', 'foo']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_train[\"new_column\"][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "    num_rows: 87599\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "squad_train = squad_train.remove_columns(\"new_column\")\n",
    "print(squad_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'heading', 'context', 'question', 'answers'],\n",
      "    num_rows: 87599\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "squad_train = squad_train.rename_column(\"title\", \"heading\")\n",
    "print(squad_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify/Update dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09af253544a54506bc8595ff0a111408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=87599.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "updated_squad_train = squad_train.map(lambda example: {'question': 'Question: ' + example['question']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Question: To whom did the Virgin Mary allegedly appear in 1858 in Lourdes '\n",
      " 'France?',\n",
      " 'Question: What is in front of the Notre Dame Main Building?',\n",
      " 'Question: The Basilica of the Sacred heart at Notre Dame is beside to which '\n",
      " 'structure?',\n",
      " 'Question: What is the Grotto at Notre Dame?',\n",
      " 'Question: What sits on top of the Main Building at Notre Dame?']\n"
     ]
    }
   ],
   "source": [
    "pprint(updated_squad_train['question'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c97f7e1c4f4d8a9fb4b53efc4075f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=87599.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['answers', 'context', 'id', 'new_heading', 'question']\n",
      "['Context: University_of_Notre_Dame',\n",
      " 'Context: University_of_Notre_Dame',\n",
      " 'Context: University_of_Notre_Dame',\n",
      " 'Context: University_of_Notre_Dame',\n",
      " 'Context: University_of_Notre_Dame']\n"
     ]
    }
   ],
   "source": [
    "updated_squad_train = squad_train.map(lambda example: {'new_heading': \"Context: \" + example['heading']}, remove_columns=['heading'])\n",
    "pprint(updated_squad_train.column_names)\n",
    "pprint(updated_squad_train['new_heading'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display examples like Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers</th>\n",
       "      <th>context</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>heading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'answer_start': [835], 'text': ['Kellermann']}</td>\n",
       "      <td>The year 1789 brought the French Revolution and with it the first division of Alsace into the départements of Haut- and Bas-Rhin. Alsatians played an active role in the French Revolution. On 21 July 1789, after receiving news of the Storming of the Bastille in Paris, a crowd of people stormed the Strasbourg city hall, forcing the city administrators to flee and putting symbolically an end to the feudal system in Alsace. In 1792, Rouget de Lisle composed in Strasbourg the Revolutionary marching song \"La Marseillaise\" (as Marching song for the Army of the Rhine), which later became the anthem of France. \"La Marseillaise\" was played for the first time in April of that year in front of the mayor of Strasbourg Philippe-Frédéric de Dietrich. Some of the most famous generals of the French Revolution also came from Alsace, notably Kellermann, the victor of Valmy, Kléber, who led the armies of the French Republic in Vendée and Westermann, who also fought in the Vendée.</td>\n",
       "      <td>57278bb15951b619008f8d09</td>\n",
       "      <td>Who led the armies of the French Republic in Vendee and Westermann?</td>\n",
       "      <td>Alsace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'answer_start': [243], 'text': ['Jean Buridan, Nicole Oresme and the Oxford Calculators']}</td>\n",
       "      <td>This new approach liberated scientific speculation from the dogmatic restraints of Aristotelian science, and paved the way for new approaches. Particularly within the field of theories of motion great advances were made, when such scholars as Jean Buridan, Nicole Oresme and the Oxford Calculators challenged the work of Aristotle. Buridan developed the theory of impetus as the cause of the motion of projectiles, which was an important step towards the modern concept of inertia. The works of these scholars anticipated the heliocentric worldview of Nicolaus Copernicus.</td>\n",
       "      <td>57275ef9708984140094dca4</td>\n",
       "      <td>Which scholars made great advances in the theories of motion?</td>\n",
       "      <td>Late_Middle_Ages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'answer_start': [189], 'text': ['Charles Mintz']}</td>\n",
       "      <td>Universal owned the rights to the \"Oswald the Lucky Rabbit\" character, although Walt Disney and Ub Iwerks had created Oswald, and their films had enjoyed a successful theatrical run. After Charles Mintz had unsuccessfully demanded that Disney accept a lower fee for producing the property, Mintz produced the films with his own group of animators. Instead, Disney and Iwerks created Mickey Mouse who in 1928 stared in the first \"sync\" sound animated short, Steamboat Willie. This moment effectively launched Walt Disney Studios' foothold, while Universal became a minor player in film animation. Universal subsequently severed its link to Mintz and formed its own in-house animation studio to produce Oswald cartoons headed by Walter Lantz.</td>\n",
       "      <td>56e14b3bcd28a01900c6775d</td>\n",
       "      <td>Who produced an Oswald the Lucky Rabbit motion picture?</td>\n",
       "      <td>Universal_Studios</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def display_random_examples(dataset=squad_train, num_examples=5):\n",
    "    assert num_examples < len(dataset)\n",
    "    \n",
    "    random_picks = []\n",
    "    for i in range(num_examples):\n",
    "        random_pick = random.randint(0,len(dataset)-1)\n",
    "        random_picks.append(random_pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[random_picks])\n",
    "    display(HTML(df.to_html()))\n",
    "        \n",
    "display_random_examples(squad_train, 3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "print(datasets.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
